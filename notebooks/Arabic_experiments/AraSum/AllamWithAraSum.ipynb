{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.data import TextDataModule, AllamDataModule\n",
    "from models.models import LitBertModel, LitXLMRobertaModel\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitXLMRobertaModel(\n",
       "  (val_accuracy): BinaryAccuracy()\n",
       "  (test_accuracy): BinaryAccuracy()\n",
       "  (train_accuracy): BinaryAccuracy()\n",
       "  (xlm_roberta): XLMRobertaForSequenceClassification(\n",
       "    (roberta): XLMRobertaModel(\n",
       "      (embeddings): XLMRobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): XLMRobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x XLMRobertaLayer(\n",
       "            (attention): XLMRobertaAttention(\n",
       "              (self): XLMRobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): XLMRobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): XLMRobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): XLMRobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): XLMRobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (train_precision): BinaryPrecision()\n",
       "  (val_precision): BinaryPrecision()\n",
       "  (test_precision): BinaryPrecision()\n",
       "  (train_recall): BinaryRecall()\n",
       "  (val_recall): BinaryRecall()\n",
       "  (test_recall): BinaryRecall()\n",
       "  (train_f1): BinaryF1Score()\n",
       "  (val_f1): BinaryF1Score()\n",
       "  (test_f1): BinaryF1Score()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LitXLMRobertaModel.load_from_checkpoint(\"trained_detectors/AllamArabicAIDetector/checkpoints/best-checkpoint.ckpt\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evaluate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AraSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = AllamDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/majed_alshaibani/Projects/ai-content-detection-dataset/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n",
      "/home/majed_alshaibani/Projects/ai-content-detection-dataset/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/majed_alshaibani/Projects/ai-content-detection-dataset/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=254` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ec7242c64941bd82e3070f53a3e4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃<span style=\"font-weight: bold\">       DataLoader 1        </span>┃<span style=\"font-weight: bold\">       DataLoader 2        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9897618889808655     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9888888597488403     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9833333492279053     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.989113450050354     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9888536334037781     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9819768667221069     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1382121592760086     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13997529447078705    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14630572497844696    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_precision_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9841743111610413     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9874316453933716     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9700104594230652     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_recall_epoch     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9947642087936401     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9910799264907837     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9953688383102417     </span>│\n",
       "└───────────────────────────┴───────────────────────────┴───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 1       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 2       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9897618889808655    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9888888597488403    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9833333492279053    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.989113450050354    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9888536334037781    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9819768667221069    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1382121592760086    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13997529447078705   \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14630572497844696   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_precision_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9841743111610413    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9874316453933716    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9700104594230652    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_recall_epoch    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9947642087936401    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9910799264907837    \u001b[0m\u001b[35m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9953688383102417    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┴───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch/dataloader_idx_0': 0.1382121592760086,\n",
       "  'test_acc_epoch/dataloader_idx_0': 0.9897618889808655,\n",
       "  'test_precision_epoch/dataloader_idx_0': 0.9841743111610413,\n",
       "  'test_recall_epoch/dataloader_idx_0': 0.9947642087936401,\n",
       "  'test_f1_epoch/dataloader_idx_0': 0.989113450050354},\n",
       " {'test_loss_epoch/dataloader_idx_1': 0.13997529447078705,\n",
       "  'test_acc_epoch/dataloader_idx_1': 0.9888888597488403,\n",
       "  'test_precision_epoch/dataloader_idx_1': 0.9874316453933716,\n",
       "  'test_recall_epoch/dataloader_idx_1': 0.9910799264907837,\n",
       "  'test_f1_epoch/dataloader_idx_1': 0.9888536334037781},\n",
       " {'test_loss_epoch/dataloader_idx_2': 0.14630572497844696,\n",
       "  'test_acc_epoch/dataloader_idx_2': 0.9833333492279053,\n",
       "  'test_precision_epoch/dataloader_idx_2': 0.9700104594230652,\n",
       "  'test_recall_epoch/dataloader_idx_2': 0.9953688383102417,\n",
       "  'test_f1_epoch/dataloader_idx_2': 0.9819768667221069}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "trainer.test(\n",
    "    model,\n",
    "    dataloaders=(\n",
    "        data_module.train_dataloader(),\n",
    "        data_module.val_dataloader(),\n",
    "        data_module.test_dataloader(),\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
